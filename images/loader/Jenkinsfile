#!groovyâ€‹

// The Fragalysis Stack (loader application) Builder.

pipeline {

  agent { label 'buildah-slave' }

  environment {
    // Registry details
    PROJECT = 'fragalysis-cicd'
    REGISTRY_USER = 'jenkins'
    REGISTRY = 'docker-registry.default:5000'
    REGISTRY_PRJ = "${REGISTRY}/${PROJECT}"
    STREAM_IMAGE = "${REGISTRY_PRJ}/loader-stream:latest"

    // get_unbuilt_data_directory environment...

    SOURCE_DATA_ROOT = '/fragalysis/django_data'
    TARGET_IMAGE = "${PROJECT}/loader-stream"
    INSIST_ON_READY = 'Yes'
    READY_FILE = 'READY'
    HOURLY_DATA = 'Yes'

    // Always push the image (whether it's new or not)
    ALWAYS_PUSH = 'No'

    // Slack channel for all notifications
    SLACK_BUILD_CHANNEL = 'dls-builds'
    // Slack channel to be used for errors/failures
    // (which also go to the CI/CD channel)
    SLACK_ALERT_CHANNEL = 'dls-alerts'

  }

  stages {

    stage('Inspect') {
      steps {
        dir('images') {
          // - Get the registry user API token (used in the Python module)
          // - Run the get_unbuilt_data_directory module to find the latest data
          // - Dump the script log.
          sh "ls ${SOURCE_DATA_ROOT}"
          script {

            // Set an environment variable based on the build trigger.
            // This way we know if the build was upstream, a timer or user-driven.
            // (see https://javadoc.jenkins.io/hudson/model/Cause.html)
            //
            // We must build the image if: -
            //
            //   DATA_ORIGIN is set (indicating a new set of data)
            //   we're the result of an upstream project or a user action
            env.CAUSE = 'DATA'
            env.FORCE_BUILD = 'No'
            def UpstreamCause = currentBuild.rawBuild.getCause(hudson.model.Cause$UpstreamCause)
            def UserIdCause = currentBuild.rawBuild.getCause(hudson.model.Cause$UserIdCause)
            def RemoteCause = currentBuild.rawBuild.getCause(hudson.model.Cause$RemoteCause)
            def TimerTriggerCause = currentBuild.rawBuild.getCause(hudson.triggers.TimerTrigger$TimerTriggerCause)
            def SCMTriggerCause = currentBuild.rawBuild.getCause(hudson.triggers.SCMTrigger$SCMTriggerCause)
            if (UpstreamCause != null) {
              env.CAUSE = 'UPSTREAM'
              env.FORCE_BUILD = 'Yes'
            } else if (UserIdCause != null) {
              env.CAUSE = 'USER'
              env.FORCE_BUILD = 'Yes'
            } else if (RemoteCause != null) {
              env.CAUSE = 'REMOTE'
            } else if (TimerTriggerCause != null) {
              env.CAUSE = 'TIMER'
            } else if (SCMTriggerCause != null) {
              env.CAUSE = 'SCM'
            }
            echo "The build cause is '${env.CAUSE}'"

          }

          // For some reason I have to separate these script
          // instructions from the previous block to avoid the exception...
          // java.io.NotSerializableException: hudson.triggers.TimerTrigger$TimerTriggerCause
          script {
            // take a look at the image in the current registry.
            // If it's built from the latest data there's nothing to do
            // (DATA_ORIGIN will be blank). If FORCE_BUILD is set then
            // the latest data will be returned.
            env.REGISTRY_USER_TOKEN = sh(script: 'oc whoami -t', returnStdout: true).trim()
            echo "FORCE_BUILD is '${env.FORCE_BUILD}'"
            env.DATA_ORIGIN = sh(script: './get_unbuilt_data_directory.py', returnStdout: true).trim()
            sh 'cat get_unbuilt_data_directory.log'
          }

        }
      }
    }

    stage('Build Image') {
      when {
        expression { DATA_ORIGIN.length() > 0 }
      }
      steps {
        dir('images/loader') {
          slackSend channel: "#${SLACK_BUILD_CHANNEL}",
                    message: "${JOB_NAME} build ${BUILD_NUMBER} - starting"
          slackSend channel: "#${SLACK_BUILD_CHANNEL}",
                    message: "${JOB_NAME} build ${BUILD_NUMBER} - using '${DATA_ORIGIN}' data"
          sh "cp -r ${SOURCE_DATA_ROOT}/${DATA_ORIGIN}/* media"
          sh "buildah bud --format docker --build-arg DATA_ORIGIN=${DATA_ORIGIN} -f Dockerfile -t ${STREAM_IMAGE} ."
        }

      }
    }

    stage('Push Image') {
      when {
        expression { DATA_ORIGIN.length() > 0 || ALWAYS_PUSH == 'Yes' }
      }
      steps {
        withCredentials([string(credentialsId: 'clusterUrl', variable: 'CLUSTER_URL'),
                         string(credentialsId: 'ocUser', variable: 'OC_USER'),
                         string(credentialsId: 'ocUserPassword', variable: 'OC_USER_PASSWORD')]) {
          script {
            TOKEN = sh(script: 'oc whoami -t', returnStdout: true).trim()
          }
          sh "podman login --tls-verify=false --username ${REGISTRY_USER} --password ${TOKEN} ${REGISTRY}"
          sh "buildah push --tls-verify=false ${STREAM_IMAGE} docker://${STREAM_IMAGE}"
          sh "podman logout ${REGISTRY}"
          sh "buildah images"

          // With a new image pushed we need to launch the Loader 'Job'.
          // But we protect ourselves from doing this if a prior
          // instance of the 'Job' is running (which would be unusual).
          // To successfully launch the Job we first delete prior instances.
          // All of this takes place in the 'deploy.sh'
          sh "oc login ${CLUSTER_URL} -u ${OC_USER} -p ${OC_USER_PASSWORD}"
          sh "oc project ${PROJECT}"
          script {
            LOADER_RUNNING = sh(script: 'oc get jobs | grep fs-loader | grep Running | wc -l', returnStdout: true).trim()
          }
          echo "RUNNING=${LOADER_RUNNING}"
        }
      }
    }

    stage('Deploy Image') {
      when {
        expression { DATA_ORIGIN.length() > 0 && LOADER_RUNNING == '0' }
      }
      steps {
        dir('images/loader') {
          sh "oc delete job --selector template=fs-loader"
          sleep 4
          sh "oc process -f fs-loader.yaml | oc create -f -"

          slackSend channel: "#${SLACK_BUILD_CHANNEL}",
                    color: 'good',
                    message: "${JOB_NAME} build ${BUILD_NUMBER} - complete"
        }
      }
    }

    stage('Blocked Image') {
      when {
        expression { DATA_ORIGIN.length() > 0 && LOADER_RUNNING != '0' }
      }
      steps {
        echo "Loader is running (deployment is blocked)"
        script {
          // Everything's OK but we were blocked from deploying it
          // as it appears a prior Job instance is running.
          // Here we just set the build status to UNSTABLE.
          currentBuild.result = 'UNSTABLE'
        }
      }
    }

  }

  // Post-job actions.
  // See https://jenkins.io/doc/book/pipeline/syntax/#post
  post {

    failure {
      slackSend channel: "#${SLACK_BUILD_CHANNEL}",
                color: 'danger',
                message: "${JOB_NAME} build ${BUILD_NUMBER} - failed (${BUILD_URL})"
      slackSend channel: "#${SLACK_ALERT_CHANNEL}",
                color: 'danger',
                message: "${JOB_NAME} build ${BUILD_NUMBER} - failed (${BUILD_URL})"
    }

    unstable {
      slackSend channel: "#${SLACK_BUILD_CHANNEL}",
                color: 'warning',
                message: "${JOB_NAME} build ${BUILD_NUMBER} - complete (unstable)"
    }

    fixed {
      slackSend channel: "#${SLACK_ALERT_CHANNEL}",
                color: 'good',
                message: "${JOB_NAME} build - fixed"
    }

  }

}
