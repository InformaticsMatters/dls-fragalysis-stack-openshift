---

# If there's a 'done' file in the standard directory
# then we skip nextflow processing. This happens
# if we're re-running and do not want to 'clean-up'.

- name: Check standard directory
  stat:
    path: "{{ standard_path }}/done"
  register: std_done_file

- import_tasks: "{{ role_path }}/../graph-processor/tasks/check-nextflow.yaml"
  when: not std_done_file.stat.exists

- name: Get raw files
  shell: >-
    {{ scripts }}/graph_get_raw_files.py
    {{ process_id }}
    {{ workflow_path }}
    --force
  environment:
    FRAGALYSIS_S3_BUCKET: "{{ s3_bucket }}"
  when:
  - not std_done_file.stat.exists
  - not nextflow_is_running
  - nextflow_run|bool

- name: Copy nextflow files
  copy:
    src: "{{ item }}"
    dest: "{{ workflow_path }}"
  loop:
  - "standard-from-raw.nf"
  - "config"
  when:
  - not std_done_file.stat.exists
  - not nextflow_is_running
  - nextflow_run|bool

- name: Set nextflow command
  set_fact:
    nextflow_cmd: >-
      nextflow -C config run standard-from-raw.nf
      --shredSize {{ process_raw_shred_size }}
      --limit {{ process_limit }}
      --skip {{ process_skip }}
      --rawPrefix '{{ process_raw_prefix }}'
      --rawType '{{ process_type }}'
      {{ nextflow_extra_args }}
      {{ nextflow_debug_args }}
  when:
  - not std_done_file.stat.exists
  - not nextflow_is_running

- name: Display nextflow command
  debug:
    var: nextflow_cmd
  when:
  - not std_done_file.stat.exists
  - not nextflow_is_running

- name: Run nextflow (async)
  command: "{{ nextflow_cmd }}"
  args:
    chdir: "{{ workflow_path }}"
  async: "{{ nextflow_timeout_minutes|int * 60 }}"
  poll: 0
  register: nextflow_async
  when:
  - not std_done_file.stat.exists
  - not nextflow_is_running
  - nextflow_run|bool

# Optionally wait for nextflow, polling at a user-defined interval...
# If the playbook is restarted the 'Wait' will not work,
# as it expects an 'ansible_job_id' which will have been lost.
# So we cannot run this if nextflow was found to be running

- name: Wait for nextflow (async)
  async_status:
    jid: "{{ nextflow_async.ansible_job_id }}"
  register: nextflow_result
  until: nextflow_result.finished
  delay: "{{ s_nextflow_poll_period_minutes|int * 60 }}"
  retries: "{{ (nextflow_timeout_minutes|int / s_nextflow_poll_period_minutes|int)|int }}"
  when:
  - not std_done_file.stat.exists
  - not nextflow_is_running
  - nextflow_run|bool

# Copy nextflow trace/report files to the build
# directory (if they exist). These will be stored on S3
# when (if) the build is saved.

- name: Copy generated standard file
  shell: cp {{ workflow_path }}/results/{{ standard_file }} {{ standard_path }}
  when:
  - not std_done_file.stat.exists
  - not nextflow_is_running
  - nextflow_run|bool

- name: Copy nextflow debug files
  shell: cp {{ workflow_path }}/{{ item }} {{ standard_path }} | true
  loop:
  - report.html
  - timeline.html
  - trace.txt
  when:
  - nextflow_debug_args|length > 0
  - not std_done_file.stat.exists
  - not nextflow_is_running
  - nextflow_run|bool

# Create a done file (to prevent re-processing)
- name: Create done file
  file:
    path: "{{ standard_path }}/done"
    state: touch
  when:
  - not std_done_file.stat.exists
  - not nextflow_is_running
  - nextflow_run|bool

# Finally, just in case the playbook failed
# and was re-executed, check nextflow status again
# and set the fact for others.

- import_tasks: "{{ role_path }}/../graph-processor/tasks/check-nextflow.yaml"
