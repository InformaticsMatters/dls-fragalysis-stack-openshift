---

# Install packages for slurm.
# As this role is applied to every node in the cluster
# we also use it to install additional things
# like Singularity and Java

- name: Install slurm packages
  yum:
    name:
    - epel-release
    - openssl
    - numactl
    - hwloc
    - lua
    - libibmad
    - libibumad

- name: Install Singularity
  yum:
    name:
    - singularity

- name: Install Java
  yum:
    name:
    - java-1.8.0-openjdk

# Install slurm from a pre-built RPM
#Â (expected to reside on the shared volume).
#
# We disable warnings on the next task because ansible
# wants us to use the yum module.

- name: Install slurm
  shell: yum --nogpgcheck localinstall -y rpmbuild/RPMS/x86_64/slurm-*.rpm
  args:
    chdir: "{{ slurm_home_path }}"
    warn: no

- name: Crete slurm group
  group:
    gid: "{{ slurm_user_id }}"
    name: slurm

- name: Crete slurm user
  user:
    name: slurm
    uid: "{{ slurm_user_id }}"
    group: slurm
    home: "{{ slurm_home_path }}"
    create_home: no
    shell: /sbin/bash

- name: Create slurm config directory
  file:
    path: /etc/slurm
    state: directory
    owner: slurm
    recurse: true

- name: Copy slurm configuration template
  template:
    src: "{{ role_path }}/files/slurm.conf.j2"
    dest: /etc/slurm/slurm.conf
    owner: slurm
  vars:
    worker_nodes: "{{ hostvars['localhost']['worker_nodes'] }}"
    head_name: "{{ slurm_instance_base_name }}-head"

- name: Copy slurm cgroup configuration
  copy:
    src: "{{ role_path }}/files/cgroup.conf"
    dest: /etc/slurm/cgroup.conf
    owner: slurm

- name: Copy slurm cgroup allowed devices configuration
  copy:
    src: "{{ role_path }}/files/cgroup_allowed_devices_file.conf"
    dest: /etc/slurm/cgroup_allowed_devices_file.conf
    owner: slurm

- name: Configure slurmd directory
  file:
    path: /var/spool/slurmd
    state: directory
    mode: 0755
    owner: slurm
    group: slurm
    recurse: true

- name: Touch slurm log
  file:
    path: /var/log/slurmd.log
    owner: slurm
    group: slurm
    state: touch
